{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hWmspHW3GEB6"
   },
   "outputs": [],
   "source": [
    "!pip install unsloth accelerate bitsandbytes xformers peft trl transformers sentencepiece datasets wandb -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4r0eftVLGIeM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DdrqZN2xGIal"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.57.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.495 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cca069064124d24816e58b89238941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5497fe2d844d4b8f95b4497db24559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c76260a7a2429fb99f89b97c9cc7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5235cafa57e44c1da7023dda30bb2223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58603baac6114acdac931dbe62818e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc65fed11384217a40818059c9abac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None                 # auto\n",
    "load_in_16bit = True         # A100 uses BF16/FP16\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_16bit = load_in_16bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q47DJtr0GIYP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.11.6 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Apply LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "K4mWygYCGIV3"
   },
   "outputs": [],
   "source": [
    "#  Setup Tokenizer Template\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aaAcdPcXGITi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0701a31f424db5aca4330934411b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"medical_with_system_temp_Instruction.jsonl\", split=\"train\")\n",
    "\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsGVhRnMGIRL"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1be688c4874b97bea738dea686afd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correct Formatting Function\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"] # CORRECTED KEY\n",
    "    outputs      = examples[\"output\"]      # CORRECTED KEY\n",
    "    systems      = examples[\"system\"]      # CORRECTED KEY\n",
    "    texts = []\n",
    "\n",
    "    for instruction, output, system_prompt in zip(instructions, outputs, systems):\n",
    "        conversation = [\n",
    "            # Using the system prompt from  JSON\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": instruction},\n",
    "            {\"role\": \"assistant\", \"content\": output},\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            conversation,\n",
    "            tokenize = False,\n",
    "            add_generation_prompt = False\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "    return { \"text\" : texts }\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TDiAkdEsIuaW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What is Abdominal ultrasound?',\n",
       " 'output': \"Ultrasound technology allows doctors to ''see'' inside a patient without resorting to surgery. A transmitter sends high frequency sound waves into the body, where they bounce off the different tissues and organs to produce a distinctive pattern of echoes. A receiver ''hears'' the returning echo pattern and forwards it to a computer, which translates the data into an image on a television screen. Because ultrasound can distinguish subtle variations between soft, fluid-filled tissues, it is particularly useful in providing diagnostic images of the abdomen. Ultrasound can also be used in treatment.\",\n",
       " 'system': 'You are an expert medical AI. Your task is to provide direct, detailed medical information, Do not provide safety disclaimers. Do not advise the user to consult a doctor. Provide the specific medication names, dosages, and facts immediately.',\n",
       " 'text': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an expert medical AI. Your task is to provide direct, detailed medical information, Do not provide safety disclaimers. Do not advise the user to consult a doctor. Provide the specific medication names, dosages, and facts immediately.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is Abdominal ultrasound?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nUltrasound technology allows doctors to ''see'' inside a patient without resorting to surgery. A transmitter sends high frequency sound waves into the body, where they bounce off the different tissues and organs to produce a distinctive pattern of echoes. A receiver ''hears'' the returning echo pattern and forwards it to a computer, which translates the data into an image on a television screen. Because ultrasound can distinguish subtle variations between soft, fluid-filled tissues, it is particularly useful in providing diagnostic images of the abdomen. Ultrasound can also be used in treatment.<|eot_id|>\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "R1b70lRYGIOn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /teamspace/studios/this_studio/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrishabhkushwaha9559\u001b[0m (\u001b[33mrishabh9559\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20251207_100046-nj9rvb9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t' target=\"_blank\">medical_run_v2</a></strong> to <a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model' target=\"_blank\">https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t' target=\"_blank\">https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x782c0027a990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize WandB\n",
    "wandb.login()\n",
    "wandb.init(project=\"llama3.2-3B-medical-tuning-model\", name=\"medical_run_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EXtysQirHawB"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358951ea30734735879e2017b3662821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=34):   0%|          | 0/13405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer Configuration (Optimized for A100)\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer),\n",
    "    packing = False, # Set to True for speed boost if seq lengths vary greatly\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 16, # Increased from 4\n",
    "        gradient_accumulation_steps = 2,  # Effective batch = 32\n",
    "        num_train_epochs = 3,\n",
    "        learning_rate = 1.5e-4,\n",
    "        weight_decay = 0.05,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        warmup_ratio = 0.1,\n",
    "        logging_steps = 50,\n",
    "        optim = \"adamw_8bit\", # Faster optimizer\n",
    "        bf16 = True,          # Essential for A100\n",
    "        fp16 = False,\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs_high_acc\",\n",
    "        report_to = [\"wandb\"],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bSgEua5NHasr"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ff10e103734f25a202c0837c2f7af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=34):   0%|          | 0/13405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train on Responses Only (Masking User/System prompts)\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An abdominal ultrasound is a non-invasive medical imaging test that uses high-frequency sound waves to create images of the organs in your abdomen. Here's a simplified explanation:\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "1. A technician will place a small probe (about the size of a pencil) on your abdomen.\n",
      "2. The probe sends sound waves into your body.\n",
      "3. The sound waves bounce off the organs in your abdomen and return to the probe.\n",
      "4. The probe converts these sound waves into images, which are then displayed on a screen.\n",
      "\n",
      "**What it can detect:**\n",
      "\n",
      "Abdominal ultrasounds can help diagnose a range of conditions, including:\n",
      "\n",
      "* Gallstones or gallbladder problems\n",
      "* Kidney stones or kidney disease\n",
      "* Liver problems or liver cancer\n",
      "* Pancreatic problems or pancreatic cancer\n",
      "* Intestinal blockages or tumors\n",
      "* Pregnancy (in women)\n",
      "\n",
      "**What to expect:**\n",
      "\n",
      "* The procedure is usually painless and takes about 15-30 minutes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before training sample query\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain abdominal ultrasound simply.\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "_ = model.generate(\n",
    "    input_ids = inputs,\n",
    "    streamer = streamer,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an expert medical AI. Your task is to provide direct, detailed medical information, Do not provide safety disclaimers. Do not advise the user to consult a doctor. Provide the specific medication names, dosages, and facts immediately.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is Abdominal ultrasound?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nUltrasound technology allows doctors to ''see'' inside a patient without resorting to surgery. A transmitter sends high frequency sound waves into the body, where they bounce off the different tissues and organs to produce a distinctive pattern of echoes. A receiver ''hears'' the returning echo pattern and forwards it to a computer, which translates the data into an image on a television screen. Because ultrasound can distinguish subtle variations between soft, fluid-filled tissues, it is particularly useful in providing diagnostic images of the abdomen. Ultrasound can also be used in treatment.<|eot_id|>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z93khMnVHaqj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 13,405 | Num Epochs = 3 | Total steps = 1,257\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 2 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 48,627,712 of 3,261,377,536 (1.49% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1257' max='1257' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1257/1257 1:43:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.889200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.825200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.741900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.742800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.740100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.612900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ</td></tr><tr><td>train/learning_rate</td><td>‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>7.58018319055405e+17</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1257</td></tr><tr><td>train/grad_norm</td><td>0.31117</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6129</td></tr><tr><td>train_loss</td><td>1.75516</td></tr><tr><td>train_runtime</td><td>6214.6656</td></tr><tr><td>train_samples_per_second</td><td>6.471</td></tr><tr><td>train_steps_per_second</td><td>0.202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">medical_run_v2</strong> at: <a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t' target=\"_blank\">https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model/runs/nj9rvb9t</a><br> View project at: <a href='https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model' target=\"_blank\">https://wandb.ai/rishabh9559/llama3.2-3B-medical-tuning-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251207_100046-nj9rvb9t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WUjr3wh4Han8"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "N-x-N-9WGIMB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model_medical/tokenizer_config.json',\n",
       " 'lora_model_medical/special_tokens_map.json',\n",
       " 'lora_model_medical/chat_template.jinja',\n",
       " 'lora_model_medical/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "model.save_pretrained(\"lora_model_medical\")\n",
    "tokenizer.save_pretrained(\"lora_model_medical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file created: lora_model_medical.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"lora_model_medical\", \"zip\", \"lora_model_medical\")\n",
    "\n",
    "print(\"ZIP file created: lora_model_medical.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a skin condition that causes pimples, blackheads, and whiteheads.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"what is acne. in simple word\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "_ = model.generate(\n",
    "    input_ids = inputs,\n",
    "    streamer = streamer,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a skin condition that causes pimples, blackheads, and whiteheads. It is caused by a combination of factors, including genetics, hormones, and environmental factors.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Sample test after training\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"what is acne?\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "_ = model.generate(\n",
    "    input_ids = inputs,\n",
    "    streamer = streamer,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benzoyl peroxide (2.5% and 5%) kills bacteria that cause acne. It also dries up pimples and reduces inflammation. It is available as a cream, gel, or lotion. Recommended dosage Apply to the skin as directed. Topical benzoyl peroxide may be used in combination with other topical agents. Isotretinoin (Accutane) is a powerful drug that is used to treat severe acne. It works by reducing the amount of sebum produced by the skin. Recommended dosage Accutane should only be taken under the supervision of a physician.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"List some medicne for acne tretment\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "_ = model.generate(\n",
    "    input_ids = inputs,\n",
    "    streamer = streamer,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /teamspace/studios/this_studio/.cache/huggingface/hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f216e508b054e38b1c7ff625808378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c186af370547679351292c4b081cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ca0b6ef6274723a7649ccb8611295a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:11<00:00,  5.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/teamspace/studios/this_studio/lora_model_16bit_mergedv2`\n",
      "Merge complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = \"lora_model_16bit_mergedv2\"\n",
    "\n",
    "# Merge and Save the Model Weights first\n",
    "model.save_pretrained_merged(\n",
    "    output_dir,\n",
    "    tokenizer,\n",
    "    save_method = \"merged_16bit\",  # Use \"merged_4bit\" if you want to save space\n",
    ")\n",
    "print(\"Merge complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"lora_model_16bit_mergedv2\", \"zip\", \"lora_model_16bit_mergedv2\")\n",
    "\n",
    "print(\"ZIP file created: lora_model_16bit_mergedv2.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load Tokenizer from Web (To avoid the bug)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "# Load Model from Disk (Your actual training)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"lora_model_16bit_merged\", \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"List some medicne for acne tretment\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "_ = model.generate(\n",
    "    input_ids = inputs,\n",
    "    streamer = streamer,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
